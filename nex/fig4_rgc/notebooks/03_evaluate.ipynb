{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83006251-8bda-4483-98d5-1c252dae17fa",
   "metadata": {},
   "source": [
    "# Generate results for panels c and e\n",
    "\n",
    "This performs the forward passes on all test data (for panel c) and on all data (for panel e)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bce24e9-d73f-4d59-a988-de9f13e245a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e532889-770d-4608-8fa5-ff064d120538",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import config\n",
    "\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "config.update(\"jax_platform_name\", \"gpu\")\n",
    "\n",
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \".8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21bb61f0-eb34-42ad-9a05-31065b0cb0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import jax.numpy as jnp\n",
    "from jax import jit, vmap, value_and_grad\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import matplotlib as mpl\n",
    "import h5py\n",
    "from functools import partial\n",
    "import jax\n",
    "import jaxlib\n",
    "\n",
    "import jaxley as jx\n",
    "\n",
    "from nex.rgc.utils.data_utils import (\n",
    "    read_data,\n",
    "    build_avg_recordings,\n",
    "    build_training_data,\n",
    ")\n",
    "from nex.rgc.utils.utils import (\n",
    "    build_cell,\n",
    "    build_kernel,\n",
    ")\n",
    "from nex.rgc.utils.rf_utils import compute_all_trained_rfs\n",
    "from nex.rgc.simulate import (\n",
    "    predict,\n",
    "    simulate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcf8a487-ec8b-4c19-bc8c-63750e210f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from warnings import simplefilter\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24200439-2aa7-4422-85bd-9ab05a023bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax 0.4.30\n",
      "jaxlib 0.4.30\n",
      "pandas 2.2.0\n",
      "numpy 1.26.4\n"
     ]
    }
   ],
   "source": [
    "print(f\"jax {jax.__version__}\")\n",
    "print(f\"jaxlib {jaxlib.__version__}\")\n",
    "print(f\"pandas {pd.__version__}\")\n",
    "print(f\"numpy {np.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c83a4fa2-e13f-425a-bcb4-8497ea5211f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_prefix = \"../../../nex/rgc\"\n",
    "results_prefix = \"results/train_runs/2024_08_01__20_57_21/0\"  # \"results/train_runs/2024_05_30__10_55_30/0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "487fcf69-4963-4674-8bb6-8b5653d49093",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_n_scan = 0\n",
    "num_datapoints_per_scanfield = 128 * 8\n",
    "nseg = 4\n",
    "cell_id = \"20161028_1\"\n",
    "rec_ids = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67d9a7ae-f747-4ab6-b6f7-6bbcefa66ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stimuli, recordings, setup, noise_full = read_data(\n",
    "    start_n_scan,\n",
    "    num_datapoints_per_scanfield,\n",
    "    cell_id,\n",
    "    rec_ids,\n",
    "    \"noise\",\n",
    "    \"..\"\n",
    ")\n",
    "\n",
    "# avg_recordings = build_avg_recordings(\n",
    "#     recordings, rec_ids, nseg, num_datapoints_per_scanfield\n",
    "# )\n",
    "# with open(\"../results/intermediate/avg_recordings.pkl\", \"wb\") as handle:\n",
    "#     pickle.dump(avg_recordings, handle)\n",
    "with open(f\"{path_prefix}/results/intermediate/avg_recordings.pkl\", \"rb\") as handle:\n",
    "    avg_recordings = pickle.load(handle)\n",
    "\n",
    "number_of_recordings_each_scanfield = list(avg_recordings.groupby(\"rec_id\").size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a0cf496-51f1-467e-97d8-314474534c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup = 5.0\n",
    "i_amp = 0.1\n",
    "\n",
    "currents, labels, loss_weights = build_training_data(\n",
    "    i_amp,\n",
    "    stimuli,\n",
    "    avg_recordings,\n",
    "    rec_ids, \n",
    "    num_datapoints_per_scanfield,\n",
    "    number_of_recordings_each_scanfield,\n",
    ")\n",
    "\n",
    "stim_branch_inds = stimuli[\"branch_ind\"].to_numpy()\n",
    "stim_comps = stimuli[\"comp\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a56b16a5-8f2d-4118-980f-9c102d289a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 0.025\n",
    "t_max = 200.0\n",
    "time_vec = np.arange(0, t_max+2*dt, dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "350b7be5-d916-4350-845a-10d9682c44f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 294 recordings\n",
      "number_of_recordings_each_scanfield [12, 6, 15, 21, 13, 10, 9, 10, 10, 6, 4, 11, 8, 4, 8]\n"
     ]
    }
   ],
   "source": [
    "with open(f\"{path_prefix}/{results_prefix}/cell.pkl\", \"rb\") as handle:\n",
    "    cell = pickle.load(handle)\n",
    "\n",
    "basal_inds = list(np.unique(cell.group_nodes[\"basal\"][\"branch_index\"].to_numpy()))\n",
    "somatic_inds = list(np.unique(cell.group_nodes[\"soma\"][\"branch_index\"].to_numpy()))\n",
    "\n",
    "cell.delete_recordings()\n",
    "cell.delete_stimuli()\n",
    "\n",
    "for i, rec in avg_recordings.iterrows():\n",
    "    cell.branch(rec[\"branch_ind\"]).loc(rec[\"comp\"]).record(\"Cai\", verbose=False)\n",
    "\n",
    "for i, rec in avg_recordings.iterrows():\n",
    "    cell.branch(rec[\"branch_ind\"]).loc(rec[\"comp\"]).record(\"v\", verbose=False)\n",
    "\n",
    "print(f\"Inserted {len(cell.recordings)} recordings\")\n",
    "print(f\"number_of_recordings_each_scanfield {number_of_recordings_each_scanfield}\")\n",
    "number_of_recordings = np.sum(number_of_recordings_each_scanfield)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5ad9a27-7053-418d-8c89-87decf1a3889",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-06 08:02:29.369396: W external/xla/xla/service/gpu/nvptx_compiler.cc:765] The NVIDIA driver's CUDA version is 12.2 which is older than the ptxas CUDA version (12.3.107). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    }
   ],
   "source": [
    "_, init_states = jx.integrate(cell, t_max=warmup, return_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cf175b2-f6fb-40ed-afed-f8ca6a1c42c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of newly added trainable parameters: 154. Total number of trainable parameters: 154\n",
      "Number of newly added trainable parameters: 154. Total number of trainable parameters: 308\n"
     ]
    }
   ],
   "source": [
    "cell.delete_trainables()\n",
    "cell.basal.branch(\"all\").make_trainable(\"axial_resistivity\")\n",
    "cell.basal.branch(\"all\").make_trainable(\"radius\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66be2052-abd6-4687-a431-ee040fe6ae81",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = build_kernel(time_vec, dt)\n",
    "output_scale = jnp.asarray(60.0)\n",
    "output_offset = jnp.asarray(-1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcccbf37-bf7a-4865-88ec-af15363e87b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{path_prefix}/{results_prefix}/opt_params/params_16.pkl\", \"rb\") as handle:\n",
    "    all_opt_params = pickle.load(handle)\n",
    "\n",
    "with open(f\"{path_prefix}/{results_prefix}/transforms/transform_params.pkl\", \"rb\") as handle:\n",
    "    transform_params = pickle.load(handle)\n",
    "\n",
    "with open(f\"{path_prefix}/{results_prefix}/transforms/transform_basal.pkl\", \"rb\") as handle:\n",
    "    transform_basal = pickle.load(handle)\n",
    "\n",
    "with open(f\"{path_prefix}/{results_prefix}/transforms/transform_somatic.pkl\", \"rb\") as handle:\n",
    "    transform_somatic = pickle.load(handle)\n",
    "\n",
    "opt_params, opt_basal_params, opt_somatic_params = all_opt_params\n",
    "\n",
    "parameters = transform_params.forward(opt_params)\n",
    "basal_neuron_params = transform_basal.forward(opt_basal_params)\n",
    "somatic_neuron_params = transform_somatic.forward(opt_somatic_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a9066b5-71ca-48fa-904e-b94558fe0cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of synaptic parameters:   287\n",
      "total number of parameters:      607\n",
      "total number of branches:        155\n"
     ]
    }
   ],
   "source": [
    "all_ = 0\n",
    "for a in all_opt_params:\n",
    "    for b in a:\n",
    "        key = list(b.keys())[0]\n",
    "        val = b[key]\n",
    "        all_ += np.prod(val.shape)\n",
    "\n",
    "print(f\"Number of synaptic parameters:   {len(all_opt_params[0][0]['w_bc_to_rgc'])}\")\n",
    "print(f\"total number of parameters:      {int(all_)}\")\n",
    "print(f\"total number of branches:        {len(all_opt_params[0][1]['axial_resistivity'])+1}\")  # Plus 1 for soma.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fef7aaf-11b8-42e1-abb9-3189e3fde27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_truncations = 4\n",
    "\n",
    "static = {\n",
    "    \"cell\": cell,\n",
    "    \"dt\": dt,\n",
    "    \"t_max\": t_max,\n",
    "    \"time_vec\": time_vec,\n",
    "    \"num_truncations\": num_truncations,\n",
    "    \"output_scale\": output_scale,\n",
    "    \"output_offset\": output_offset,\n",
    "    \"kernel\": kernel,\n",
    "    \"somatic_inds\": somatic_inds,\n",
    "    \"basal_inds\": basal_inds,\n",
    "    \"stim_branch_inds\": stim_branch_inds,\n",
    "    \"stim_comps\": stim_comps,\n",
    "}\n",
    "vmapped_predict = jit(vmap(partial(predict, static=static), in_axes=(None, None, None, 0, None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d43f515-fe18-4827-8a90-9ade02c99178",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(split_images, split_labels, split_currents, split_masks):\n",
    "    num_batches = 15\n",
    "    batch_size_eval = 128 * 8\n",
    "    num = 128 * 8\n",
    "    num_batches = int(np.ceil(len(split_masks) / batch_size_eval))\n",
    "    print(\"num batches\", num_batches)\n",
    "    batches = range(num_batches)\n",
    "    \n",
    "    all_ca_predictions = []\n",
    "    all_ca_predictions_untrained = []\n",
    "    all_ca_recordings = []\n",
    "    all_images = []\n",
    "    all_masks = []\n",
    "    \n",
    "    for k in batches:\n",
    "        print(\"k\", k)\n",
    "    \n",
    "        test_images = split_images[:, :, k*batch_size_eval:k*batch_size_eval+num]\n",
    "        test_currents = split_currents[k*batch_size_eval:k*batch_size_eval+num]\n",
    "    \n",
    "        all_images.append(test_images)\n",
    "        all_ca_recordings.append(split_labels[k*batch_size_eval:k*batch_size_eval+num])\n",
    "        all_masks.append(split_masks[k*batch_size_eval:k*batch_size_eval+num])\n",
    "    \n",
    "        # Trained.\n",
    "        ca_predictions = vmapped_predict(\n",
    "            parameters,\n",
    "            basal_neuron_params,\n",
    "            somatic_neuron_params,\n",
    "            test_currents,\n",
    "            init_states,\n",
    "        )\n",
    "        all_ca_predictions.append(ca_predictions)\n",
    "    \n",
    "    \n",
    "    all_images = np.concatenate(all_images, axis=2)\n",
    "    all_ca_recordings = np.concatenate(all_ca_recordings, axis=0)\n",
    "    all_ca_predictions = np.concatenate(all_ca_predictions, axis=0)\n",
    "    all_masks = np.concatenate(all_masks, axis=0)\n",
    "\n",
    "    return all_images, all_ca_recordings, all_ca_predictions, all_masks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc1ffe5-f13e-4221-a523-f8270dfb36d7",
   "metadata": {},
   "source": [
    "### Panel c: Calcium vs model correlation plot; based on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ebbcc87-5e40-4400-8e76-847d88a0e89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{path_prefix}/{results_prefix}/data/train_inds.pkl\", \"rb\") as handle:\n",
    "    train_inds = pickle.load(handle)\n",
    "\n",
    "with open(f\"{path_prefix}/{results_prefix}/data/val_inds.pkl\", \"rb\") as handle:\n",
    "    val_inds = pickle.load(handle)\n",
    "\n",
    "with open(f\"{path_prefix}/{results_prefix}/data/test_inds.pkl\", \"rb\") as handle:\n",
    "    test_inds = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b0b2338-58d6-4a22-a1e6-1871d58d2088",
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = test_inds\n",
    "split_images = noise_full[:, :, inds]\n",
    "split_labels = labels[inds]\n",
    "split_currents = currents[inds]\n",
    "split_masks = loss_weights[inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "655b8bed-25a9-4423-9921-4ddd0a1575c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num batches 3\n",
      "k 0\n",
      "k 1\n",
      "k 2\n"
     ]
    }
   ],
   "source": [
    "test_images, test_ca_recordings, test_ca_predictions, test_masks = evaluate(\n",
    "    split_images, split_labels, split_currents, split_masks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86a76721-65e4-4c4e-ad4a-c71b69608abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 0.24699644990499506\n",
      "max 0.5119800747722698\n",
      "std 0.12544279124008825\n",
      "larger > 0 146 out of 147\n"
     ]
    }
   ],
   "source": [
    "rhos = []\n",
    "for roi_id in range(147):\n",
    "    roi_was_measured = test_masks[:, roi_id].astype(bool)\n",
    "\n",
    "    rho_trained = np.corrcoef(\n",
    "        test_ca_recordings[roi_was_measured, roi_id], \n",
    "        test_ca_predictions[roi_was_measured, roi_id]\n",
    "    )[0, 1]\n",
    "    rhos.append(rho_trained)\n",
    "print(\"mean\", np.mean(rhos))\n",
    "print(\"max\", np.max(rhos))\n",
    "print(\"std\", np.std(rhos))\n",
    "print(\"larger > 0\", np.sum(np.asarray(rhos) > 0.0), \"out of\", len(rhos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7527195f-c2fb-4e1c-9c3c-a3491843bbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_ids = np.cumsum([0] + number_of_recordings_each_scanfield)[:-1]\n",
    "\n",
    "with open(\"../results/03_results/test_images.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(test_images, handle)\n",
    "\n",
    "with open(\"../results/03_results/test_ca_recordings.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(test_ca_recordings, handle)\n",
    "\n",
    "with open(\"../results/03_results/test_ca_predictions.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(test_ca_predictions, handle)\n",
    "\n",
    "with open(\"../results/03_results/test_masks.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(test_masks, handle)\n",
    "\n",
    "with open(\"../results/03_results/roi_ids.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(roi_ids, handle)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03fad34-bd3b-45c4-81a8-bf90e943c4ca",
   "metadata": {},
   "source": [
    "# Panel e: forward sims for receptive fields, based on merged train/val/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc6ac466-c092-41bb-a7e7-a73e23004562",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_images = noise_full\n",
    "split_labels = labels\n",
    "split_currents = currents\n",
    "split_masks = loss_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b245dd3e-9007-4870-8675-da61c925e24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num batches 15\n",
      "k 0\n",
      "k 1\n",
      "k 2\n",
      "k 3\n",
      "k 4\n",
      "k 5\n",
      "k 6\n",
      "k 7\n",
      "k 8\n",
      "k 9\n",
      "k 10\n",
      "k 11\n",
      "k 12\n",
      "k 13\n",
      "k 14\n"
     ]
    }
   ],
   "source": [
    "all_images, all_ca_recordings, all_ca_predictions, all_masks = evaluate(\n",
    "    split_images, split_labels, split_currents, split_masks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c2a0e67d-a70f-43b8-bc0c-a41260bdee0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 0.2520464123394455\n",
      "max 0.46443021518596933\n",
      "std 0.11246235871375339\n",
      "larger > 0: 147 out of 147\n"
     ]
    }
   ],
   "source": [
    "rhos = []\n",
    "for roi_id in range(147):\n",
    "    roi_was_measured = all_masks[:, roi_id].astype(bool)\n",
    "\n",
    "    rho_trained = np.corrcoef(\n",
    "        all_ca_recordings[roi_was_measured, roi_id], \n",
    "        all_ca_predictions[roi_was_measured, roi_id]\n",
    "    )[0, 1]\n",
    "    rhos.append(rho_trained)\n",
    "print(\"mean\", np.mean(rhos))\n",
    "print(\"max\", np.max(rhos))\n",
    "print(\"std\", np.std(rhos))\n",
    "print(\"larger > 0:\", np.sum(np.asarray(rhos) > 0.0), \"out of\", len(rhos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6c969bb1-b78f-40c1-82ac-d8bfcd393510",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../results/03_results/all_images.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(all_images, handle)\n",
    "\n",
    "with open(\"../results/03_results/all_ca_recordings.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(all_ca_recordings, handle)\n",
    "\n",
    "with open(\"../results/03_results/all_ca_predictions.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(all_ca_predictions, handle)\n",
    "\n",
    "with open(\"../results/03_results/all_masks.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(all_masks, handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94c8088-cfea-443f-b506-3896a437acf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
