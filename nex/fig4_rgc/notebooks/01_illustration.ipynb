{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e906a142-ea50-4347-b82b-480cc38163c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "import matplotlib as mpl\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import jaxley as jx\n",
    "from jaxley.channels import HH\n",
    "from jaxley_mech.channels.fm97 import Na, K, KA, KCa, Ca, Leak\n",
    "import jax.numpy as jnp\n",
    "from jax import jit, vmap\n",
    "from tensorflow.data import Dataset\n",
    "\n",
    "import pickle\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18629d07-4070-4f59-822e-4e6b47e5f520",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_id = \"20161028_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43ec40d2-9bb6-4eee-b2e5-6da4ee3aa28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stimuli_meta = pd.read_pickle(f\"../results/data/stimuli_meta_{cell_id}.pkl\")\n",
    "bc_output = pd.read_pickle(f\"../results/data/off_bc_output_{cell_id}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3ddffc1-d541-45fc-a3fe-51318585f96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_output = bc_output[bc_output[\"cell_id\"] == \"20161028_1\"]\n",
    "bc_output = bc_output[bc_output[\"rec_id\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83cc0435-780c-4d6e-ad52-0f112a790909",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_or_test = \"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0dec7696-f56f-4a32-a48d-c4783bcce55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_n_scan = 0 if train_or_test == \"train\" else 128 * 4\n",
    "num_datapoints_per_scanfield = 128 * 4 if train_or_test == \"train\" else 128 * 1\n",
    "cell_id = \"20161028_1\"  # \"20170610_1\", \"20161028_1\"\n",
    "rec_ids = [1,2,9,14,15]  # 1,2,9,14,15 vs 1,4,5,6,8\n",
    "# somatic: 1,3,4,7,10,12\n",
    "# medium: 2,5,7,10\n",
    "# far: 9, 11, 13, 14, 15\n",
    "\n",
    "# Only loaded for visualization.\n",
    "file = h5py.File(\"../data/noise.h5\", 'r+')\n",
    "noise_stimulus = file[\"k\"][()]\n",
    "noise_stimulus = noise_stimulus[:, :, start_n_scan:start_n_scan+num_datapoints_per_scanfield]\n",
    "noise_full = np.concatenate([noise_stimulus for _ in range(len(rec_ids))], axis=2)\n",
    "\n",
    "setup = pd.read_pickle(\"../results/data/setup.pkl\")\n",
    "recording_meta = pd.read_pickle(\"../results/data/recording_meta.pkl\")\n",
    "stimuli_meta = pd.read_pickle(f\"../results/data/stimuli_meta_{cell_id}.pkl\")\n",
    "labels_df = pd.read_pickle(f\"../results/data/labels_lowpass_{cell_id}.pkl\")\n",
    "\n",
    "# TODO Change to file that contains all outputs.\n",
    "bc_output = pd.read_pickle(f\"../results/data/off_bc_output_{cell_id}.pkl\")\n",
    "\n",
    "setup = setup[setup[\"cell_id\"] == cell_id]\n",
    "setup = setup[setup[\"rec_id\"].isin(rec_ids)]\n",
    "\n",
    "stimuli_meta = stimuli_meta[stimuli_meta[\"cell_id\"] == cell_id]\n",
    "\n",
    "bc_output = bc_output[bc_output[\"cell_id\"] == cell_id]\n",
    "bc_output = bc_output[bc_output[\"rec_id\"].isin(rec_ids)]\n",
    "\n",
    "recording_meta = recording_meta[recording_meta[\"cell_id\"] == cell_id]\n",
    "recording_meta = recording_meta[recording_meta[\"rec_id\"].isin(rec_ids)]\n",
    "\n",
    "labels_df = labels_df[labels_df[\"cell_id\"] == cell_id]\n",
    "labels_df = labels_df[labels_df[\"rec_id\"].isin(rec_ids)]\n",
    "\n",
    "# Contrain the number of labels.\n",
    "constrained_ca_activities = np.stack(labels_df[\"ca\"].to_numpy())[:, start_n_scan:start_n_scan+num_datapoints_per_scanfield].tolist()\n",
    "labels_df[\"ca\"] = constrained_ca_activities\n",
    "\n",
    "constrained_activities = np.stack(bc_output[\"activity\"].to_numpy())[:, start_n_scan:start_n_scan+num_datapoints_per_scanfield].tolist()\n",
    "bc_output[\"activity\"] = constrained_activities\n",
    "\n",
    "# Contrain the number of stimulus images.\n",
    "bc_output_concatenated = bc_output.groupby(\"bc_id\", sort=False)[\"activity\"].apply(lambda x: list(chain(*list(x))))\n",
    "\n",
    "# Constrain to a single rec_id because, apart from the activity (which is dealt with above) the bc_outputs have the same info for every scanfield.\n",
    "bc_output = bc_output[bc_output[\"rec_id\"] == rec_ids[0]]\n",
    "bc_output[\"activity\"] = list(bc_output_concatenated.to_numpy())\n",
    "\n",
    "# Join stimulus dfs.\n",
    "stimuli = stimuli_meta.join(bc_output.set_index(\"bc_id\"), on=\"bc_id\", how=\"left\", rsuffix=\"_bc\")\n",
    "stimuli = stimuli.drop(columns=\"cell_id_bc\")\n",
    "\n",
    "# Join recording dfs.\n",
    "labels_df[\"unique_id\"] = labels_df[\"rec_id\"] * 100 + labels_df[\"roi_id\"]\n",
    "recording_meta[\"unique_id\"] = recording_meta[\"rec_id\"] * 100 + recording_meta[\"roi_id\"]\n",
    "recordings = recording_meta.join(labels_df.set_index(\"unique_id\"), on=\"unique_id\", how=\"left\", rsuffix=\"_ca\")\n",
    "recordings = recordings.drop(columns=[\"cell_id_ca\", \"rec_id_ca\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31d6d83-69c2-4f9f-a111-f7506b0c7107",
   "metadata": {},
   "source": [
    "# Illustration of the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "008cf634-35c6-4bf8-ac9d-baa1c22932dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../results/01_illustration/bc_output.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(bc_output, handle)\n",
    "\n",
    "with open(\"../results/01_illustration/recordings.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(recordings, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "544cd2c4-111f-43a5-ac19-f94fdeed4dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPL hyperparameters.\n",
    "gaussian_kernel_std = 20.0\n",
    "kernel_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ccbb3b04-cfa2-435a-8287-60e6663cfcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_filter(spatial_axis, std=50):\n",
    "    amp1 = 1 / std\n",
    "    gaussian1 = amp1 * np.exp(-spatial_axis**2 / std**2)\n",
    "    return gaussian1\n",
    "\n",
    "def build_opl_kernel(filter: str, std, filter_size):\n",
    "    res_filter = 100\n",
    "    center = [0., 0.]\n",
    "    \n",
    "    pos_x = np.linspace(-filter_size, filter_size, res_filter)\n",
    "    pos_y = np.linspace(-filter_size, filter_size, res_filter)\n",
    "    X, Y = np.meshgrid(pos_x, pos_y)\n",
    "    \n",
    "    dist_x = center[0] - X\n",
    "    dist_y = center[1] - Y\n",
    "    \n",
    "    dists = np.sqrt(dist_x**2 + dist_y**2)\n",
    "\n",
    "    if filter == \"Gaussian\":\n",
    "        kernel = gaussian_filter(dists, std) / 100.0\n",
    "    elif filter == \"center_surround\":\n",
    "        raise NotImplementedError\n",
    "        kernel = center_surround_filter(dists) / 100.0\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "    return kernel, X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f14f5a6d-7f99-4ea7-ae4d-46a1a44d53fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel, X, Y = build_opl_kernel(\"Gaussian\", gaussian_kernel_std, kernel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c6b707c8-2c67-4844-a2c0-31dfb17fdca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../results/01_illustration/kernel_x.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(X, handle)\n",
    "\n",
    "with open(\"../results/01_illustration/kernel_y.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(Y, handle)\n",
    "\n",
    "with open(\"../results/01_illustration/kernel_z.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(kernel, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc4e443e-9482-4d51-b557-f50a4332f870",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BipolarCell:\n",
    "    \"\"\"Given input current, return output of bipolar cells.\"\"\"\n",
    "\n",
    "    def __init__(self, max_input):\n",
    "        self.x_vals = [-100, -50, -25, -12.5, -6.75, -3, 3, 6.75, 12.5, 25.0, 50.0, 100.0]\n",
    "        self.response = [-0.05, -0.12, -0.15, -0.1, -0.08, -0.03, 0.1, 0.18, 0.37, 0.64, 0.85, 1.0]\n",
    "        self.intensity = (1.0 + 1.0 / 100 * np.asarray(self.x_vals)) / 2.0\n",
    "\n",
    "        # To scale the input-output curve, we have to know the maximal input current.\n",
    "        self.max_input = max_input\n",
    "\n",
    "    def __call__(self, input):\n",
    "        standardized_bc_input = input / self.max_input\n",
    "        bc_output = np.interp(standardized_bc_input, self.intensity, self.response)\n",
    "        return bc_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e090040d-e2f5-4cb1-99be-09c345fae23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bc = BipolarCell(1.0)\n",
    "inputs = np.linspace(-0.1, 1.1, 100)\n",
    "vals = bc(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "16a7da52-3f91-4b1a-ad2a-86f50b03957f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../results/01_illustration/nonlinearity_inputs.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(inputs, handle)\n",
    "\n",
    "with open(\"../results/01_illustration/nonlinearity_vals.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(vals, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd6c192-ba80-4483-af63-5c899c6904b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
